{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Crash Course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import sys, os, glob \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the data\n",
    "# make a toy dataset with 1000 samples\n",
    "np.random.seed(0)\n",
    "n = 1000 # number of samples\n",
    "x = np.random.rand(n, 1)\n",
    "y = 2 * x + 1 + (0.1 * np.random.randn(n, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor = torch.tensor(x, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset\n",
    "class SimpleDataset(Dataset):\n",
    "\n",
    "    def __init__(self, x, y):\n",
    "        super(SimpleDataset, self).__init__()\n",
    "        self.x_data = x\n",
    "        self.y_data = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "dataset = SimpleDataset(x_tensor, y_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into train and test\n",
    "train_prop = 0.8 # 80%\n",
    "train_size = int(train_prop * len(dataset)) # .80 * 1000 = 800\n",
    "train_idx = np.random.choice(len(dataset), train_size, replace=False) # random sample 800 indices, w/o replacement\n",
    "test_idx = np.setdiff1d(np.arange(len(dataset)), train_idx) # get the indices that are not in train_idx\n",
    "\n",
    "train_dataset = Subset(dataset, train_idx) \n",
    "test_dataset = Subset(dataset, test_idx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating a Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # architecture: fc (1 -> 64) -> ReLU -> fc (64 -> 1)\n",
    "        self.fc1 = nn.Linear(1, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # is is a 1D tensor\n",
    "        x = self.fc1(x) # 8x1 -> 8x64\n",
    "        x = self.act(x) # 8x64\n",
    "        x = self.fc2(x) # 8x64 -> 8x1\n",
    "\n",
    "        return x\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** Now that we've created a quick dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.6342]) tensor([0.2638], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x, y = train_dataset[0]\n",
    "y_pred = model(x)\n",
    "print(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
